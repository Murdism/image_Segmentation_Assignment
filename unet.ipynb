{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_tensor(input,target):\n",
    "    diff =input.size()[2] - target.size()[2] # difference in width\n",
    "    diff = diff // 2\n",
    "    print(\"Difffffffffffffff: \",diff,input.size()[2],target.size()[2])\n",
    "    return(input[:,diff:input.size()[2]-diff,diff:input.size()[2]-diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,IN_CHANNELS=3):\n",
    "        super().__init__() \n",
    "        self.encode_conv1 = conv_block(IN_CHANNELS, 64)\n",
    "        self.encode_conv2 = conv_block(64, 128)\n",
    "        self.encode_conv3 = conv_block(128, 256)\n",
    "        self.encode_conv4 = conv_block(256, 512)\n",
    "        self.encode_conv5 = conv_block(512, 1024)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.decode_conv1 = nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n",
    "        #self.decode_conv1 = nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.encode_conv1(x)\n",
    "        x2 = self.maxpool(x1)\n",
    "        x3 = self.encode_conv2(x2)\n",
    "        x4 = self.maxpool(x3)\n",
    "        x5 = self.encode_conv3(x4)\n",
    "        x6 = self.maxpool(x5)\n",
    "        x7 = self.encode_conv4(x6)\n",
    "        x8 = self.maxpool(x7)\n",
    "        x9 = self.encode_conv5(x8)\n",
    "\n",
    "        \n",
    "        # Decoder x1,x3,x5,x7 will be used as input \n",
    "        x10 = self.decode_conv1(x9)\n",
    "        x7_cropped = crop_tensor(x7,x10)\n",
    "        print(\" x1 : \",x1.size())\n",
    "        print(\"\\nx2 : \",x2.size())\n",
    "        print(\"\\nx3 : \",x3.size())\n",
    "        print(\"\\nx4 : \",x4.size())\n",
    "        print(\"\\nx5 : \",x5.size())\n",
    "        print(\"\\nx6 : \",x6.size())\n",
    "        print(\"\\nx7 : \",x7.size())\n",
    "        print(\"\\nx8 : \",x8.size())\n",
    "        print(\"\\nx9 : \",x9.size())\n",
    "        print(\"\\nx10 : \",x10.size())\n",
    "        print(\"\\nx7_cropped : \",x7_cropped.size())\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "        # self.max_pool = nn.MaxPool(kerner_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difffffffffffffff:  4 30 22\n",
      " x1 :  torch.Size([64, 296, 296])\n",
      "\n",
      "x2 :  torch.Size([64, 148, 148])\n",
      "\n",
      "x3 :  torch.Size([128, 144, 144])\n",
      "\n",
      "x4 :  torch.Size([128, 72, 72])\n",
      "\n",
      "x5 :  torch.Size([256, 68, 68])\n",
      "\n",
      "x6 :  torch.Size([256, 34, 34])\n",
      "\n",
      "x7 :  torch.Size([512, 30, 30])\n",
      "\n",
      "x8 :  torch.Size([512, 15, 15])\n",
      "\n",
      "x9 :  torch.Size([1024, 11, 11])\n",
      "\n",
      "x10 :  torch.Size([512, 22, 22])\n",
      "\n",
      "x11 :  torch.Size([512, 22, 22])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand((3,300,300)).to(device)\n",
    "print(model(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x10.size:  torch.Size([2, 512, 36, 36])\n",
      "x7.size:  torch.Size([2, 512, 37, 37])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [200, 64, 300, 300]           1,792\n",
      "              ReLU-2        [200, 64, 300, 300]               0\n",
      "            Conv2d-3        [200, 64, 300, 300]          36,928\n",
      "              ReLU-4        [200, 64, 300, 300]               0\n",
      "         MaxPool2d-5        [200, 64, 150, 150]               0\n",
      "            Conv2d-6       [200, 128, 150, 150]          73,856\n",
      "              ReLU-7       [200, 128, 150, 150]               0\n",
      "            Conv2d-8       [200, 128, 150, 150]         147,584\n",
      "              ReLU-9       [200, 128, 150, 150]               0\n",
      "        MaxPool2d-10         [200, 128, 75, 75]               0\n",
      "           Conv2d-11         [200, 256, 75, 75]         295,168\n",
      "             ReLU-12         [200, 256, 75, 75]               0\n",
      "           Conv2d-13         [200, 256, 75, 75]         590,080\n",
      "             ReLU-14         [200, 256, 75, 75]               0\n",
      "        MaxPool2d-15         [200, 256, 37, 37]               0\n",
      "           Conv2d-16         [200, 512, 37, 37]       1,180,160\n",
      "             ReLU-17         [200, 512, 37, 37]               0\n",
      "           Conv2d-18         [200, 512, 37, 37]       2,359,808\n",
      "             ReLU-19         [200, 512, 37, 37]               0\n",
      "        MaxPool2d-20         [200, 512, 18, 18]               0\n",
      "           Conv2d-21        [200, 1024, 18, 18]       4,719,616\n",
      "             ReLU-22        [200, 1024, 18, 18]               0\n",
      "           Conv2d-23        [200, 1024, 18, 18]       9,438,208\n",
      "             ReLU-24        [200, 1024, 18, 18]               0\n",
      "  ConvTranspose2d-25         [200, 512, 36, 36]       2,097,664\n",
      "================================================================\n",
      "Total params: 20,940,864\n",
      "Trainable params: 20,940,864\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 205.99\n",
      "Forward/backward pass size (MB): 72922.85\n",
      "Params size (MB): 79.88\n",
      "Estimated Total Size (MB): 73208.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# batchsize, channels,height,width\n",
    "summary(model, input_size = (3,300, 300),batch_size=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('segmentation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c6cf681ed52ccdf5461de7f00a5396296db5e0f2a58b4d6a57334ba109c144f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
